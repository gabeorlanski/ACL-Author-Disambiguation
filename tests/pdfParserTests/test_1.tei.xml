<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/gabe/research/grobid-master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.6-SNAPSHOT" ident="GROBID" when="2019-08-02T11:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Branch and Bound Algorithm for Dependency Parsing with Non-local Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Ryan McDonald</publisher>
				<availability status="unknown"><p>Copyright Ryan McDonald</p>
				</availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">The University of Texas at Dallas</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<email>yangl@hlt.utdallas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">The University of Texas at Dallas</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Branch and Bound Algorithm for Dependency Parsing with Non-local Features</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Transactions of the Association for Computational Linguistics</title>
						<imprint>
							<publisher>Ryan McDonald</publisher>
							<biblScope unit="volume">1</biblScope>
							<biblScope unit="page" from="37" to="48"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<note type="submission">Submitted 11/2012; Revised 2/2013; Published 3/2013. c 2013 Association for Computational Linguistics.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Graph based dependency parsing is inefficient when handling non-local features due to high computational complexity of inference. In this paper, we proposed an exact and efficient decoding algorithm based on the Branch and Bound (B&amp;B) framework where nonlocal features are bounded by a linear combination of local features. Dynamic programming is used to search the upper bound. Experiments are conducted on English PTB and Chinese CTB datasets. We achieved competitive Unlabeled Attachment Score (UAS) when no additional resources are available: 93.17% for English and 87.25% for Chinese. Parsing speed is 177 words per second for English and 97 words per second for Chinese. Our algorithm is general and can be adapted to nonprojective dependency parsing or other graphical models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For graph based projective dependency parsing, dynamic programming (DP) is popular for decoding due to its efficiency when handling local features. It performs cubic time parsing for arc-factored models <ref type="bibr" target="#b11">(Eisner, 1996;</ref><ref type="bibr" target="#b22">McDonald et al., 2005a)</ref> and biquadratic time for higher order models with richer sibling and grandchild features <ref type="bibr" target="#b5">(Carreras, 2007;</ref>. However, for models with general non-local features, DP is inefficient.</p><p>There have been numerous studies on global inference algorithms for general higher order parsing. One popular approach is reranking <ref type="bibr" target="#b8">(Collins, 2000;</ref><ref type="bibr" target="#b6">Charniak and Johnson, 2005;</ref><ref type="bibr" target="#b12">Hall, 2007)</ref>. It typically has two steps: the low level classifier generates the top k hypotheses using local features, then the high level classifier reranks these candidates using global features. Since the reranking quality is bounded by the oracle performance of candidates, some work has combined candidate generation and reranking steps using cube pruning <ref type="bibr" target="#b14">(Huang, 2008;</ref><ref type="bibr" target="#b33">Zhang and McDonald, 2012)</ref> to achieve higher oracle performance. They parse a sentence in bottom up order and keep the top k derivations for each span using k best parsing <ref type="bibr" target="#b13">(Huang and Chiang, 2005)</ref>. After merging the two spans, non-local features are used to rerank top k combinations. This approach is very efficient and flexible to handle various nonlocal features. The disadvantage is that it tends to compute non-local features as early as possible so that the decoder can utilize that information at internal spans, hence it may miss long historical features such as long dependency chains.</p><p>Smith and Eisner modeled dependency parsing using Markov Random Fields (MRFs) with global constraints and applied loopy belief propagation (LBP) for approximate learning and inference <ref type="bibr" target="#b28">(Smith and Eisner, 2008)</ref>. Similar work was done for Combinatorial Categorial Grammar (CCG) parsing <ref type="bibr" target="#b0">(Auli and Lopez, 2011)</ref>. They used posterior marginal beliefs for inference to satisfy the tree constraint: for each factor, only legal messages (satisfying global constraints) are considered in the partition function.</p><p>A similar line of research investigated the use of integer linear programming (ILP) based parsing <ref type="bibr" target="#b26">(Riedel and Clarke, 2006;</ref><ref type="bibr" target="#b20">Martins et al., 2009</ref>). This method is very expressive. It can handle arbitrary non-local features determined or bounded by linear inequalities of local features. For local models, LP is less efficient than DP. The reason is that, DP works on a small number of dimensions in each recursion, while for LP, the popular revised simplex method needs to solve a m dimensional linear system in each iteration <ref type="bibr" target="#b25">(Nocedal and Wright, 2006)</ref>, where m is the number of constraints, which is quadratic in sentence length for projective dependency parsing <ref type="bibr" target="#b20">(Martins et al., 2009)</ref>.</p><p>Dual Decomposition (DD) ) is a special case of Lagrangian relaxation. It relies on standard decoding algorithms as oracle solvers for sub-problems, together with a simple method for forcing agreement between the different oracles. This method does not need to consider the tree constraint explicitly, as it resorts to dynamic programming which guarantees its satisfaction. It works well if the sub-problems can be well defined, especially for joint learning tasks. However, for the task of dependency parsing, using various non-local features may result in many overlapped sub-problems, hence it may take a long time to reach a consensus <ref type="bibr" target="#b21">(Martins et al., 2011)</ref>.</p><p>In this paper, we propose a novel Branch and Bound (B&amp;B) algorithm for efficient parsing with various non-local features. B&amp;B <ref type="bibr" target="#b19">(Land and Doig, 1960)</ref> is generally used for combinatorial optimization problems such as ILP. The difference between our method and ILP is that the sub-problem in ILP is a relaxed LP, which requires a numerical solution, while ours bounds the non-local features by a linear combination of local features and uses DP for decoding as well as calculating the upper bound of the objective function. An exact solution is achieved if the bound is tight. Though in the worst case, time complexity is exponential in sentence length, it is practically efficient especially when adopting a pruning strategy.</p><p>Experiments are conducted on English PennTree Bank and Chinese Tree Bank 5 (CTB5) with standard train/develop/test split. We achieved 93.17% Unlabeled Attachment Score (UAS) for English at a speed of 177 words per second and 87.25% for Chinese at a speed of 97 words per second.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Graph Based Parsing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>Given a sentence x = x 1 , x 2 , . . . , x n where x i is the i th word of the sentence, dependency parsing assigns exactly one head word to each word, so that dependencies from head words to modifiers form a tree. The root of the tree is a special symbol denoted by x 0 which has exactly one modifier. In this paper, we focus on unlabeled projective dependency parsing but our algorithm can be adapted for labeled or non-projective dependency parsing <ref type="bibr" target="#b23">(McDonald et al., 2005b)</ref>.</p><p>The inference problem is to search the optimal parse tree y *</p><formula xml:id="formula_0">y * = arg max y∈Y(x) ϕ(x, y)</formula><p>where Y(x) is the set of all candidate parse trees of sentence x. ϕ(x, y) is a given score function which is usually decomposed into small parts</p><formula xml:id="formula_1">ϕ(x, y) = ∑ c⊆y ϕ c (x)<label>(1)</label></formula><p>where c is a subset of edges, and is called a factor. For example, in the all grandchild model , the score function can be represented as ϕ(x, y) = ∑ e hm ∈y ϕ e hm (x) + ∑ e gh ,e hm ∈y ϕ e gh ,e hm (x)</p><p>where the first term is the sum of scores of all edges x h → x m , and the second term is the sum of the scores of all edge chains x g → x h → x m . In discriminative models, the score of a parse tree y is the weighted sum of the fired feature functions, which can be represented by the sum of the factors</p><formula xml:id="formula_2">ϕ(x, y) = w T f (x, y) = ∑ c⊆y w T f (x, c) = ∑ c⊆y ϕ c (x)</formula><p>where f (x, c) is the feature vector that depends on c. For example, we could define a feature for grand-</p><formula xml:id="formula_3">child c = {e gh , e hm } f (x, c) =      1 if x g = would ∧ x h = be ∧x m = happy ∧ c is selected 0 otherwise</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dynamic Programming for Local Models</head><p>In first order models, all factors c in Eq(1) contain a single edge. The optimal parse tree can be derived by DP with running time O(n 3 ) <ref type="bibr" target="#b11">(Eisner, 1996)</ref>. The algorithm has two types of structures: complete span, which consists of a headword and its descendants on one side, and incomplete span, which consists of a dependency and the region between the head and modifier. It starts at single word spans, and merges the spans in bottom up order. For second order models, the score function ϕ(x, y) adds the scores of siblings (adjacent edges with a common head) and grandchildren There are two versions of second order models, used respectively by <ref type="bibr" target="#b5">Carreras (2007)</ref> and . The difference is that Carreras' only considers the outermost grandchildren, while Koo and Collin's allows all grandchild features. Both models permit O(n 4 ) running time. Third-order models score edge triples such as three adjacent sibling modifiers, or grand-siblings that score a word, its modifier and its adjacent grandchildren, and the inference complexity is O(n 4 ) .</p><p>In this paper, for all the factors/features that can be handled by DP, we call them the local factors/features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Idea</head><p>For general high order models with non-local features, we propose to use Branch and Bound (B&amp;B) algorithm to search the optimal parse tree. A B&amp;B algorithm has two steps: branching and bounding. The branching step recursively splits the search space Y(x) into two disjoint subspaces Y(x) = Y 1 ∪ Y 2 by fixing assignment of one edge. For each subspace Y i , the bounding step calculates the upper bound of the optimal parse tree score in the subspace: U B Y i ≥ max y∈Y i ϕ(x, y). If this bound is no more than any obtained parse tree score U B Y i ≤ ϕ(x, y ′ ), then all parse trees in subspace Y i are no more optimal than y ′ , and Y i could be pruned safely.</p><p>The efficiency of B&amp;B depends on the branching strategy and upper bound computation. For example, <ref type="bibr">Sun et al. (2012)</ref> used B&amp;B for MRFs, where they proposed two branching strategies and a novel data structure for efficient upper bound computation. <ref type="bibr" target="#b15">Klenner and Ailloud (2009)</ref> proposed a variation of Balas algorithm <ref type="bibr" target="#b1">(Balas, 1965)</ref> for coreference resolution, where candidate branching variables are sorted by their weights.</p><p>Our bounding strategy is to find an upper bound for the score of each non-local factor c containing multiple edges. The bound is the sum of new scores of edges in the factor plus a constant</p><formula xml:id="formula_4">ϕ c (x) ≤ ∑ e∈c ψ e (x) + α c</formula><p>Based on the new scores {ψ e (x)} and constants {α c }, we define the new score of parse tree y</p><formula xml:id="formula_5">ψ(x, y) = ∑ c⊆y ( ∑ e∈c ψ e (x) + α c ) Then we have ψ(x, y) ≥ ϕ(x, y), ∀y ∈ Y(x)</formula><p>The advantage of such a bound is that, it is the sum of new edge scores. Hence, its optimum tree max y∈Y(x) ψ(x, y) can be found by DP, which is the upper bound of max y∈Y(x) ϕ(x, y), as for any y ∈ Y(x), ψ(x, y) ≥ ϕ(x, y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Upper Bound Function</head><p>In this section, we derive the upper bound function ψ(x, y) described above. To simplify notation, we drop x throughout the rest of the paper. Let z c be a binary variable indicating whether factor c is selected in the parse tree. We reformulate the score function in Eq(1) as</p><formula xml:id="formula_6">ϕ(y) ≡ ϕ(z) = ∑ c ϕ c z c<label>(2)</label></formula><p>Correspondingly, the tree constraint is replaced by z ∈ Z. Then the parsing task is</p><formula xml:id="formula_7">z * = arg max z∈Z ϕ c z c<label>(3)</label></formula><p>Notice that, for any z c , we have</p><formula xml:id="formula_8">z c = min e∈c z e</formula><p>which means that factor c appears in parse tree if and only if all its edges {e|e ∈ c} are selected in the tree.</p><p>Here z e is short for z {e} for simplicity. Our bounding method is based on the following fact: for a set {a 1 , a 2 , . . . a r } (a j denotes the j th element) , its minimum</p><formula xml:id="formula_9">min{a j } = min p∈∆ ∑ j p j a j<label>(4)</label></formula><p>where ∆ is probability simplex</p><formula xml:id="formula_10">∆ = {p|p j ≥ 0, ∑ j p j = 1}</formula><p>We discuss the bound for ϕ c z c in two cases: ϕ c ≥ 0 and ϕ c &lt; 0.</p><p>If ϕ c ≥ 0, we have</p><formula xml:id="formula_11">ϕ c z c = ϕ c min e∈c z e = ϕ c min pc∈∆ ∑ e∈c p e c z e = min p c ∈∆ ∑ e∈c ϕ c p e c z e</formula><p>The second equation comes from Eq(4). For simplicity, let</p><formula xml:id="formula_12">g c (p c , z) = ∑ e∈c ϕ c p e c z e with domain domg c = {p c ∈ ∆; z e ∈ {0, 1}, ∀e ∈ c}. Then we have ϕ c z c = min p c g c (p c , z)<label>(5)</label></formula><p>If ϕ c &lt; 0, we have two upper bounds. One is commonly used in ILP when all the variables are binary</p><formula xml:id="formula_13">a * = min j {a j } r j=1 ⇔ a * ≤ a j a * ≥ ∑ j a j − (r − 1)</formula><p>According to the last inequality, we have the upper bound for negative scored factors</p><formula xml:id="formula_14">ϕ c z c ≤ ϕ c ( ∑ e∈c z e − (r c − 1) ) (6)</formula><p>where r c is the number of edges in c. For simplicity, we use the notation</p><formula xml:id="formula_15">σ c (z) = ϕ c ( ∑ e∈c z e − (r c − 1) )</formula><p>The other upper bound when ϕ c &lt; 0 is simple</p><formula xml:id="formula_16">ϕ c z c ≤ 0<label>(7)</label></formula><p>Notice that, for any parse tree, one of the upper bounds must be tight. Eq <ref type="formula">(6)</ref> is tight if c appears in the parse tree: z c = 1, otherwise Eq <ref type="formula" target="#formula_16">(7)</ref> is tight. Therefore</p><formula xml:id="formula_17">ϕ c z c = min {σ c (z), 0} Let h c (p c , z) = p 1 c σ c (z) + p 2 c · 0 with domh c = {p c ∈ ∆; z e ∈ {0, 1}, ∀e ∈ c}.</formula><p>According to Eq(4), we have</p><formula xml:id="formula_18">ϕ c z c = min pc h c (p c , z) (8) Let ψ(p, z) = ∑ c,ϕc≥0 g c (p c , z) + ∑ c,ϕc&lt;0 h c (p c , z)</formula><p>Minimize ψ with respect to p, we have</p><formula xml:id="formula_19">min p ψ(p, z) = min p   ∑ c,ϕ c ≥0 g c (p c , z) + ∑ c,ϕ c &lt;0 h c (p c , z)   = ∑ c,ϕ c ≥0 min p c g c (p c , z) + ∑ c,ϕ c &lt;0 min p c h c (p c , z) = ∑ c,ϕ c ≥0 ϕ c z c + ∑ c,ϕ c &lt;0 ϕ c z c = ϕ(z)</formula><p>The second equation holds since, for any two factors, c and c ′ , g c (or h c ) and g c ′ (or h c ′ ) are separable. The third equation comes from Eq(5) and Eq <ref type="formula">(8)</ref>.</p><p>Based on this, we have the following proposition:</p><p>Proposition 1. For any p, p c ∈ ∆, and z ∈ Z, ψ(p, z) ≥ ϕ(z). Therefore, ψ(p, z) is an upper bound function of ϕ(z). Furthermore, fixing p, ψ(p, z) is a linear function of z e , see Eq(5) and Eq <ref type="formula">(8)</ref>, variables z c for large factors are eliminated. Hence z ′ = arg max z ψ(p, z) can be solved efficiently by DP.</p><p>Because</p><formula xml:id="formula_20">ψ(p, z ′ ) ≥ ψ(p, z * ) ≥ ϕ(z * ) ≥ ϕ(z ′ )</formula><p>after obtaining z ′ , we get the upper bound and lower bound of ϕ(z * ): ψ(p, z ′ ) and ϕ(z ′ ).</p><p>The upper bound is expected to be as tight as possible. Using min-max inequality, we get</p><formula xml:id="formula_21">max z∈Z ϕ(z) = max z∈Z min p ψ(p, z) ≤ min p max z∈Z ψ(p, z)</formula><p>which provides the tightest upper bound of ϕ(z * ).</p><p>Since ψ is not differentiable w.r.t p, projected sub-gradient <ref type="bibr" target="#b4">(Calamai and Moré, 1987;</ref> is used to search the saddle point. More specifically, in each iteration, we first fix p and search z using DP, then we fix z and update p by</p><formula xml:id="formula_22">p new = P ∆ ( p + ∂ψ ∂p α )</formula><p>where α &gt; 0 is the step size in line search, function P ∆ (q) denotes the projection of q onto the probability simplex ∆. In this paper, we use Euclidean projection, that is</p><formula xml:id="formula_23">P ∆ (q) = min p∈∆ ∥p − q∥ 2</formula><p>which can be solved efficiently by sorting <ref type="bibr" target="#b10">(Duchi et al., 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Branch and Bound Based Parsing</head><p>As discussed in Section 3.1, the B&amp;B recursive procedure yields a binary tree structure called Branch and Bound tree. Each node of the B&amp;B tree has some fixed z e , specifying some must-select edges and must-remove edges. The root of the B&amp;B tree has no constraints, so it can produce all possible parse trees including z * . Each node has two children. One adds a constraint z e = 1 for a free edge z = e1 0 1</p><formula xml:id="formula_24">0 1 0 1 z = e2 ψ φ =9 =4 ψ&lt;LB ψ φ =8 =5 ψ φ =7 =4 ψ φ =7 =4 ψ φ =7 =5 ψ φ =4 =3 ψ φ =6 =2 min p max z∈Z z e 1 =0 z e 2 =1</formula><p>ψ(p, z) 6 <ref type="figure">Figure 1</ref>: A part of B&amp;B tree. ϕ, ψ are short for ϕ(z ′ ) and ψ(p ′ , z ′ ) respectively. For each node, some edges of the parse tree are fixed. All parse trees that satisfy the fixed edges compose the subset of S ⊆ Z. A min-max problem is solved to get the upper bound and lower bound of the optimal parse tree over S. Once the upper bound ψ is less than LB, the node is removed safely.</p><p>e and the other fixes z e = 0. We can explore the search space {z|z e ∈ {0, 1}} by traversing the B&amp;B tree in breadth first order.</p><p>Let S ⊆ Z be subspace of parse trees satisfying the constraint, i.e., in the branch of the node. For each node in B&amp;B tree, we solve</p><formula xml:id="formula_25">p ′ , z ′ = arg min p max z∈S ψ(p, z)</formula><p>to get the upper bound and lower bound of the best parse tree in S. A global lower bound LB is maintained which is the maximum of all obtained lower bounds. If the upper bound of the current node is lower than the global lower bound, the node can be pruned from the B&amp;B tree safely. An example is shown in <ref type="figure">Figure 1</ref>.</p><p>When the upper bound is not tight: ψ &gt; LB, we need to choose a good branching variable to generate the child nodes. Let G(z ′ ) = ψ(p ′ , z ′ ) − ϕ(z ′ ) denote the gap between the upper bound and lower bound. This gap is actually the accumulated gaps of all factors c. Let G c be the gap of c</p><formula xml:id="formula_26">G c = { g c (p ′ c , z ′ ) − ϕ c z ′ c if ϕ c ≥ 0 h c (p ′ c , z ′ ) − ϕ c z ′ c if ϕ c &lt; 0</formula><p>We choose the branching variable heuristically: for each edge e, we define its gap as the sum of the gaps of factors that contain it</p><formula xml:id="formula_27">G e = ∑ c,e∈c G c</formula><p>The edge with the maximum gap is selected as the branching variable. Suppose there are N nodes on a level of B&amp;B tree, and correspondingly, we get N branching variables, among which, we choose the one with the highest lower bound as it likely reaches the optimal value faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Lower Bound Initialization</head><p>A large lower bound is critical for efficient pruning. In this section, we discuss an alternative way to initialize the lower bound LB. We apply the similar trick to get the lower bound function of ϕ(z).</p><p>Similar to Eq <ref type="formula">(8)</ref>, for ϕ c ≥ 0, we have</p><formula xml:id="formula_28">ϕ c z c = max{ϕ c ( ∑ e∈c z e − (r c − 1) ) , 0} = max{σ c (z), 0}</formula><p>Using the fact that</p><formula xml:id="formula_29">max{a j } = max p∈∆ ∑ j p j a j we have ϕ c z c = max p c ∈∆ p 1 c σ c (z) + p 2 c · 0 = max pc h c (p c , z) For ϕ c &lt; 0, we have ϕ c z c = max e∈c {ϕ c z e } = max pc∈∆ ∑ e∈c p e c ϕ c z e = max pc g c (p c , z)</formula><p>Put the two cases together, we get the lower bound function</p><formula xml:id="formula_30">π(p, z) = ∑ c,ϕ c ≥0 h c (p c , z) + ∑ c,ϕ c &lt;0 g c (p c , z)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Branch and Bound based parsing</head><p>Require: {ϕ c } Ensure: Optimal parse tree z * Solve p * , z * = arg max p,z π(p, z)</p><formula xml:id="formula_31">Initialize S = {Z}, LB = π(p * , z * ) while S ̸ = ∅ do Set S ′ = ∅{nodes that survive from pruning} foreach S ∈ S Solve min p max z ψ(p, z) to get LB S , U B S LB = max{LB, LB S∈S }, update z * foreach S ∈ S, add S to S ′ , if U B S &gt; LB Select a branching variable z e . Clear S = ∅ foreach S ∈ S ′ Add S 1 = {z|z ∈ S, z e = 1} to S Add S 2 = {z|z ∈ S, z e = 0} to S. end while</formula><p>For any p, p c ∈ ∆, z ∈ Z π(p, z) ≤ ϕ(z) π(p, z) is not concave, however, we could alternatively optimize z and p to get a good approximation, which provides a lower bound for ϕ(z * ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Summary</head><p>We summarize our B&amp;B algorithm in Algorithm 1.</p><p>It is worth pointing out that so far in the above description, we have used the assumption that the backbone DP uses first order models, however, the backbone DP can be the second or third order version. The difference is that, for higher order DP, higher order factors such as adjacent siblings, grandchildren are directly handled as local factors.</p><p>In the worst case, all the edges are selected for branching, and the complexity grows exponentially in sentence length. However, in practice, it is quite efficient, as we will show in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>The datasets we used are the English Penn Tree Bank (PTB) and Chinese Tree Bank 5.0 (CTB5). We use the standard train/develop/test split as described in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>We extracted dependencies using Joakim Nivre's Penn2Malt tool with standard head rules: Yamada and Matsumoto's <ref type="bibr" target="#b31">(Yamada and Matsumoto, 2003)</ref>    <ref type="bibr" target="#b32">(Zhang and Clark, 2008)</ref> for Chinese. Unlabeled attachment score (UAS) is used to evaluate parsing quality 1 . The B&amp;B parser is implemented with C++. All the experiments are conducted on the platform Intel Core i5-2500 CPU 3.30GHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline: DP Based Second Order Parser</head><p>We use the dynamic programming based second order parser <ref type="bibr" target="#b5">(Carreras, 2007)</ref> as the baseline. Averaged structured perceptron <ref type="bibr" target="#b9">(Collins, 2002)</ref> is used for parameter estimation. We determine the number of iterations on the validation set, which is 6 for both corpora.</p><p>For English, we train the POS tagger using linear chain perceptron on training set, and predict POS tags for the development and test data. The parser is trained using the automatic POS tags generated by 10 fold cross validation. For Chinese, we use the gold standard POS tags.</p><p>We use five types of features: unigram features, bigram features, in-between features, adjacent sibling features and outermost grand-child features. The first three types of features are firstly introduced by <ref type="bibr" target="#b22">McDonald et al. (2005a)</ref> and the last two types of features are used by <ref type="bibr" target="#b5">Carreras (2007)</ref>. All the features are the concatenation of surrounding words, lower cased words (English only), word length (Chinese only), prefixes and suffixes of words (Chinese only), POS tags, coarse POS tags which are derived from POS tags using a simple mapping table, distance between head and modifier, direction of edges. For English, we used 674 feature templates to generate large amounts of features, and finally got 86.7M non-zero weighted features after training. The baseline parser got 92.81% UAS on the testing set. For Chinese, we used 858 feature templates, and finally got 71.5M non-zero weighted features after train-ing. The baseline parser got 86.89% UAS on the testing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">B&amp;B Based Parser with Non-local Features</head><p>We use the baseline parser as the backbone of our B&amp;B parser. We tried different types of non-local features as listed below:</p><p>• All grand-child features. Notice that this feature can be handled by Koo's second order model  directly.</p><p>• All great grand-child features.</p><p>• All sibling features: all the pairs of edges with common head. An example is shown in <ref type="figure">Figure</ref> 2.</p><p>• All tri-sibling features: all the 3-tuples of edges with common head.</p><p>• Comb features: for any word with more than 3 consecutive modifiers, the set of all the edges from the word to the modifiers form a comb. 2</p><p>• Hand crafted features: We perform cross validation on the training data using the baseline parser, and designed features that may correct the most common errors. We designed 13 hand-craft features for English in total. One example is shown in <ref type="figure">Figure 3</ref>. For Chinese, we did not add any hand-craft features, as the errors in the cross validation result vary a lot, and we did not find general patterns to fix them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Implementation Details</head><p>To speed up the solution of the min-max subproblem, for each node in the B&amp;B tree, we initialize p with the optimal solution of its parent node, since the child node fixes only one additional edge, its optimal point is likely to be closed to its parent's. For the root node of B&amp;B tree, we initialize p e c = regulation occurs through inaction , rather than through ... <ref type="figure">Figure 3</ref>: An example of hand-craft feature: for the word sequence A . . . rather than A, where A is a preposition, the first A is the head of than, than is the head of rather and the second A.</p><p>negative weighted factors.</p><p>Step size α is initialized with max c,ϕ c ̸ =0 { 1 |ϕ c | }, as the vector p is bounded in a unit box. α is updated using the same strategy as . Two stopping criteria are used. One is 0 ≤ ψ old − ψ new ≤ ϵ, where ϵ &gt; 0 is a given precision 3 . The other checks if the bound is tight: U B = LB. Because all features are boolean (note that they can be integer), their weights are integer during each perceptron update, hence the scores of parse trees are discrete. The minimal gap between different scores is 1 N ×T after averaging, where N is the number of training samples, and T is the iteration number for perceptron training. Therefore the upper bound can be tightened as U B = ⌊N T ψ⌋ N T . During testing, we use the pre-pruning method as used in <ref type="bibr" target="#b20">Martins et al. (2009)</ref> for both datasets to balance parsing quality and speed. This method uses a simple classifier to select the top k candidate heads for each word and exclude the other heads from search space. In our experiment, we set k = 10.   <ref type="bibr" target="#b2">Bohnet and Kuhn (2012)</ref> 93.39 87.5 Systems using additional resources <ref type="bibr" target="#b30">Suzuki et al. (2009)</ref> 93.79 N/A <ref type="bibr" target="#b17">Koo et al. (2008)</ref> 93.5 N/A <ref type="bibr" target="#b7">Chen et al. (2012)</ref> 92.76 N/A <ref type="table">Table 2</ref>: Comparison between our system and thestate-of-art systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Main Result</head><p>Experimental results are listed in <ref type="table">Table 2</ref>. For comparison, we also include results of representative state-of-the-art systems. For the third order parser, we re-implemented Model 1 , and removed the longest sentence in the CTB dataset, which contains 240 words, due to the O(n 4 ) space complexity 4 . For ILP based parsing, we used TurboParser 5 , a speed-optimized parser toolkit. We trained full models (which use all grandchild features, all sibling features and head bigram features <ref type="bibr" target="#b21">(Martins et al., 2011)</ref>) for both datasets using its default settings. We also list the performance in its documentation on English corpus. The observation is that, the all-sibling features are most helpful for our parser, as some good sibling features can not be encoded in DP based parser. For example, a matched pair of parentheses are always siblings, but their head may lie between them. An-other observation is that all great grandchild features and all tri-sibling features slightly hurt the performance and we excluded them from the final system.</p><p>When no additional resource is available, our parser achieved competitive performance: 93.17% Unlabeled Attachment Score (UAS) for English at a speed of 177 words per second and 87.25% for Chinese at a speed of 97 words per second. Higher UAS is reported by joint tagging and parsing <ref type="bibr" target="#b3">(Bohnet and Nivre, 2012)</ref> or system integration <ref type="bibr" target="#b2">(Bohnet and Kuhn, 2012)</ref> which benefits from both transition based parsing and graph based parsing. Previous work shows that combination of the two parsing techniques can learn to overcome the shortcomings of each non-integrated system <ref type="bibr" target="#b24">(Nivre and McDonald, 2008;</ref><ref type="bibr" target="#b32">Zhang and Clark, 2008)</ref>. System combination will be an interesting topic for our future research. The highest reported performance on English corpus is 93.79%, obtained by semisupervised learning with a large amount of unlabeled data <ref type="bibr" target="#b30">(Suzuki et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Tradeoff Between Accuracy and Speed</head><p>In this section, we study the trade off between accuracy and speed using different pre-pruning setups.</p><p>In <ref type="table" target="#tab_4">Table 3</ref>, we show the parsing accuracy and inference time in testing stage with different numbers of candidate heads k in pruning step. We can see that, on English dataset, when k ≥ 10, our parser could gain 2 − 3 times speedup without losing much parsing accuracy. There is a further increase of the speed with smaller k, at the cost of some accuracy. Compared with TurboParser, our parser is less efficient but more accurate. <ref type="bibr" target="#b33">Zhang and McDonald (2012)</ref> is a state-of-the-art system which adopts cube pruning for efficient parsing. Notice that, they did not use pruning which seems to increase parsing speed with little hit in accuracy. Moreover, they did labeled parsing, which also makes their speed not directly comparable.</p><p>For each node of B&amp;B tree, our parsing algorithm uses projected sub-gradient method to find the saddle point, which requires a number of calls to a DP, hence the efficiency of Algorithm 1 is mainly determined by the number of DP calls. <ref type="figure" target="#fig_3">Figure 4 and</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Polynomial Non-local Factors</head><p>Our bounding strategy can handle a family of nonlocal factors that can be expressed as a polynomial function of local factors. To see this, suppose</p><formula xml:id="formula_32">z c = ∑ i α i ∏ e∈E i z e</formula><p>For each i, we introduce new variable z E i = min e∈E i z e . Because z e is binary, z E i = ∏ e∈E i z e . In this way, we replace z c by several z E i that can be handled by our bounding strategy.</p><p>We give two examples of these polynomial nonlocal factors. First is the OR of local factors: z c = max{z e , z ′ e }, which can be expressed by z c = z e + z ′ e −z e z ′ e . The second is the factor of valency feature  <ref type="figure">Figure 5</ref> Averaged number of Calls to DP relative to sentence length with different pruning settings, k denotes the number of candidate heads of each word in pruning step. <ref type="bibr" target="#b20">(Martins et al., 2009)</ref>. Let binary variable v ik indicate whether word i has k modifiers. Given {z e } for the edges with head i, then {v ik |k = 1, . . . , n − 1} can be solved by</p><formula xml:id="formula_33">∑ k k j v ik = ( ∑ e z e ) j 0 ≤ j ≤ n − 1</formula><p>The left side of the equation is the linear function of v ik . The right side of the equation is a polynomial function of z e . Hence, v ik could be expressed as a polynomial function of z e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">k Best Parsing</head><p>Though our B&amp;B algorithm is able to capture a variety of non-local features, it is still difficult to handle many kinds of features, such as the depth of the parse tree. Hence, a reranking approach may be useful in order to incorporate such information, where k parse trees can be generated first and then a second pass model is used to rerank these candidates based on more global or non-local features. In addition, k-best parsing may be needed in many applications to use parse information and especially utilize information from multiple candidates to optimize taskspecific performance. We have not conducted any experiment for k best parsing, hence we only discuss the algorithm. According to proposition 1, we have Proposition 2. Given p and subset S ⊆ Z, let z k denote the k th best solution of max z∈S ψ(p, z). If a parse tree z ′ ∈ S satisfies ϕ(z ′ ) ≥ ψ(p, z k ), then z ′ is one of the k best parse trees in subset S.</p><p>Proof. Since z k is the k th best solution of ψ(p, z), for z j , j &gt; k, we have ψ(p, z k ) ≥ ψ(p, z j ) ≥ ϕ(z j ). Since the size of the set {z j |j &gt; k} is |S| − k, hence there are at least |S| − k parse trees whose scores ϕ(z j ) are less than ψ(p, z k ). Because ϕ(z ′ ) ≥ ψ(p, z k ), hence z ′ is at least the k th best parse tree in subset S.</p><p>Therefore, we can search the k best parse trees in this way: for each sub-problem, we use DP to derive the k best parse trees. For each parse tree z, if ϕ(z) ≥ ψ(p, z k ), then z is selected into the k best set. Algorithm terminates until the k th bound is tight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we proposed a new parsing algorithm based on a Branch and Bound framework. The motivation is to use dynamic programming to search for the bound. Experimental results on PTB and CTB5 datasets show that our method is competitive in terms of both performance and efficiency. Our method can be adapted to non-projective dependency parsing, as well as the k best MST algorithm <ref type="bibr" target="#b12">(Hall, 2007)</ref> to find the k best candidates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>e</head><label></label><figDesc>gh ,e hm ∈y ϕ e hm ,e gh (x) + ∑ e hm ,e hs ∈y ϕ e hm ,e hs (x)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of all sibling features. Top: a sub-tree; Bottom: extracted sibling features. Existing higher order DP systems can not handle the siblings on both sides of head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>3 we use ϵ = 10 −8 in our implementation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4</head><label>4</label><figDesc>Figure 4 Averaged parsing time (seconds) relative to sentence length with different pruning settings, k denotes the number of candidate heads of each word in pruning step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Data split in our experiment for English, and Zhang and Clark's</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Fig- ure 5 show the averaged parsing time and number of calls to DP relative to the sentence length with differ- ent pruning settings. Parsing time grows smoothly</figDesc><table>PTB 
CTB 
System 
UAS 
w/s UAS 
w/s 
Ours (no prune) 
93.18 
52 87.28 
73 
Ours (k = 20) 
93.17 
105 87.28 
76 
Ours (k = 10) 
93.17 
177 87.25 
97 
Ours (k = 5) 
93.10 
264 86.94 
108 
Ours (k = 3) 
92.68 
493 85.76 
128 
TurboParser(full) 
92.82 
402 86.05 
192 
TurboParser(standard) 92.68 
638 85.80 
283 
TurboParser(basic) 
90.97 4670 82.28 2736 
Zhang and McDon-
ald (2012) 

 † 

93.06 
220 86.87 N/A 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Trade off between parsing accuracy (UAS) and speed (words per second) with different pre- pruning settings. k denotes the number of candi- date heads of each word preserved for B&amp;B parsing. † Their speed is not directly comparable as they per- forms labeled parsing without pruning. when sentence length ≤ 40. There is some fluctua- tion for the long sentences. This is because there are very few sentences for a specific long length (usual- ly 1 or 2 sentences), and the statistics are not stable or meaningful for the small samples. Without pruning, there are in total 132, 161 calls to parse 2, 416 English sentences, that is, each sen- tence requires 54.7 calls on average. For Chinese, there are 84, 645 calls for 1, 910 sentences, i.e., 44.3 calls for each sentence on average.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For English, we follow Koo and Collins (2010) and ignore any word whose gold-standard POS tag is one of { " " : , .}. For Chinese, we ignore any word whose POS tag is PU.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In fact, our algorithm can deal with non-consecutive modifiers; however, in such cases, factor detection (detect regular expressions like x 1 . * x 2 . * . . . ) requires the longest common subsequence algorithm (LCS), which is time-consuming if many comb features are generated. Similar problems arise for sub-tree features, which may contain many non-consecutive words.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">In fact, Koo's algorithm requires only O(n 3 ) space. Our implementation is O(n 4 ) because we store the feature vectors for fast training. 5 http://www.ark.cs.cmu.edu/TurboParser/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We'd like to thank Hao Zhang, Andre Martins and Zhenghua Li for their helpful discussions. We also thank Ryan McDonald and three anonymous reviewers for their valuable comments. This work is partly supported by DARPA under Contract No. HR0011-12-C-0016 and FA8750-13-2-0041. Any opinions expressed in this material are those of the authors and do not necessarily reflect the views of DARPA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comparison of loopy belief propagation and dual decomposition for integrated CCG supertagging and parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An additive algorithm for solving linear programs with zero-one variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Egon</forename><surname>Balas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The best of bothworlds -a graph-based completion model for transition-based parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP-CoNLL</title>
		<meeting>of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Projected gradient methods for linearly constrained problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Calamai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Moré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Experiments with a higher-order projective dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLPCoNLL</title>
		<meeting>of EMNLPCoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coarse-tofine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Utilizing dependency language models for graph-based dependency parsing models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discriminative reranking for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient projections onto the l1-ball for learning in high dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Three new probabilistic models for dependency parsing: an exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">K-best spanning tree parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Better k-best parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWPT</title>
		<meeting>of IWPT</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Forest reranking: Discriminative parsing with non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimization in coreference resolution is not needed: A nearly-optimal algorithm with intensional constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Klenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ailloud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient thirdorder dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Simple semi-supervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dual decomposition for parsing with non-projective head automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An automatic method of solving discrete programming problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ailsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><forename type="middle">G</forename><surname>Land</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="497" to="520" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Concise integer linear programming formulations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dual decomposition with many overlapping components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Aguiar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT-EMNLP</title>
		<meeting>of HLT-EMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Integrating graph-based and transition-based dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Numerical Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Incremental integer linear programming for non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On dual decomposition and linear programming relaxations for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dependency parsing by belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Honglak Lee, and Silvio Savarese. 2012. Efficient and exact MAP-MRF inference using branch and bound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murali</forename><surname>Telaprolu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AISTATS</title>
		<meeting>of AISTATS</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An empirical study of semi-supervised structured conditional models for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Statistical dependency analysis with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWPT</title>
		<meeting>of IWPT</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalized higher-order dependency parsing with cube pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with rich non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
